{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cell 1: Setup and Master Configuration\n**This cell handles all installations, imports, model downloads, and contains a single configuration section for all your settings.**","metadata":{}},{"cell_type":"code","source":"# ==============================================================================\n#  1. SETUP: INSTALL AND IMPORT LIBRARIES\n# ==============================================================================\n# For local environments (like Anaconda), uncomment these lines to install libraries.\n# !pip install pandas openpyxl transformers torch tqdm textblob seaborn nltk scikit-learn\n# !pip install huggingface_hub[hf_xet]\n# !pip install --upgrade Pillow==9.5.0\n\n# --- Import Libraries ---\nimport pandas as pd\nimport os\nimport re\nimport string\nimport numpy as np\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport spacy\nfrom transformers import pipeline\nfrom tqdm.auto import tqdm\nfrom textblob import TextBlob\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk import FreqDist, bigrams, trigrams\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.metrics import silhouette_score\nfrom openpyxl.drawing.image import Image\nfrom gensim.corpora.dictionary import Dictionary\nfrom gensim.models.coherencemodel import CoherenceModel\nfrom gensim.models.ldamodel import LdaModel\n\n# --- Download NLP Models ---\n# This section ensures all necessary data models are available.\nnltk.download('punkt', quiet=True)\nnltk.download('stopwords', quiet=True)\nnltk.download('wordnet', quiet=True)\nnltk.download('vader_lexicon', quiet=True)\nnltk.download('omw-1.4', quiet=True)\nnltk.download('brown', quiet=True) # For TextBlob\n!python -m textblob.download_corpora --quiet\n!python -m spacy download en_core_web_md --quiet\n\n# Register tqdm for use with pandas .progress_apply()\ntqdm.pandas(desc=\"Processing Verbatims\")\n\n# ==============================================================================\n#  2. 🔴 MASTER USER CONFIGURATION 🔴\n# ==============================================================================\n\n# --- Input File Details ---\n# For Kaggle, the path is typically '/kaggle/input/your-dataset-name/your-file-name.xlsx'\nFILE_PATH = r'/kaggle/input/on-survey-20250922-02/EMEA CSAT BR0922.xlsx'\nTEXT_COLUMN_NAME = 'star_rating_comment'\n\n# --- Output File Details ---\nOUTPUT_FOLDER_PATH = r'/kaggle/working/' # Correct for Kaggle\nPROGRAM_NAME = \"On\"\nKPIS_IN_SCOPE = \"EMEA\"\nLOBS_IN_SCOPE = \"20250922\"\nMAJOR_VERSION = 1 # Manually change for new datasets or category versions\n\n# --- Analysis Settings ---\nCUSTOM_STOP_WORDS = {\n    # --- Generic Business & Service Terms ---\n    'company', 'business', 'service', 'services', 'product', 'products', 'team', 'customer', \n    'customers', 'client', 'clients', 'staff', 'agent', 'representative', 'organization',\n    'experience', 'issue', 'issues', 'problem', 'problems', 'question', 'questions', \n    'feedback', 'inquiry', 'inquiries', 'request', 'requests', 'ticket', 'case', 'account',\n\n    # --- Common Vague Fillers & Conversational Terms ---\n    'also', 'really', 'actually', 'always', 'just', 'like', 'im', 'ive', 'thing', 'things', \n    'something', 'anything', 'everything', 'well', 'get', 'got', 'getting', 'would', 'could', \n    'should', 'make', 'made', 'one', 'even', 'since', 'every', 'time', 'times', 'day', 'days', \n    'week', 'weeks', 'month', 'months', 'year', 'years', 'lot',\n\n    # --- Politeness, Greetings, & Inquiries ---\n    'please', 'help', 'hello', 'hi', 'hey', 'thank', 'thanks', 'appreciate', 'regards', 'best', \n    'know', 'see', 'want', 'wanted', 'looking', 'wondering', 'information', 'info', 'details',\n    \n    # --- Placeholders for Your Specific Names ---\n    'company',str(PROGRAM_NAME),str(KPIS_IN_SCOPE),str(LOBS_IN_SCOPE),\n\n    # --- Prepositions ---\n    'aboard', 'about', 'above', 'across', 'after', 'against', 'along', 'among', 'around', 'at',\n    'before', 'behind', 'below', 'beneath', 'beside', 'between', 'beyond', 'by', 'down', 'during',\n    'for', 'from', 'in', 'inside', 'into', 'like', 'near', 'of', 'off', 'on', 'onto', 'out',\n    'outside', 'over', 'past', 'since', 'through', 'throughout', 'to', 'toward', 'under',\n    'underneath', 'until', 'up', 'upon', 'with', 'within', 'without',\n}\n\nCLASSIFICATION_THRESHOLD = 0.45 # Confidence score (0.0 to 1.0) for categorization\n\n# --- Define Your Zero-Shot Categories and Sub-Categories (Granular Version) ---\nCATEGORIES = {\n    # --- People Driven Categories ---\n    'Interaction with Call Center Agent': [\n        \"Call agent's communication and listening skills\",\n        \"Call agent's knowledge and problem-solving ability\",\n        \"Call agent's attitude empathy and professionalism\",\n        \"Efficiency and speed of call handling or resolution\",\n    ],\n    'Interaction with In-Store Staff': [\n        \"In-store staff's helpfulness and attitude\",\n        \"Staff's product knowledge and ability to answer questions\",\n        \"Availability and attentiveness of staff in the store\",\n        \"Efficiency of in-store processes like checkout or returns\",\n    ],\n    'Interaction with Field Technician': [\n        \"Technician's professionalism, timeliness, and communication\",\n        \"Technician's skill and ability to fix the issue\",\n        \"Cleanliness and care taken by the technician in the home\",\n        \"Explanation of work performed by the technician\",\n    ],\n\n    # --- Process Driven Category ---\n    'Company Process or Policy Issue': [\n        'Confusion or disagreement with a company policy',\n        'The overall process was too complex or had too many steps',\n        'The total time it took to resolve the issue',\n        'Problems with a follow-up, callback, or promised contact',\n    ],\n\n    # --- Technical and System Categories ---\n    'Website or Online Portal Issue': [\n        \"Website was slow, lagging, or unresponsive\",\n        'Difficulty navigating or finding information on the website',\n        'A website bug, glitch, or error message',\n        'The website crashed, froze, or was unavailable',\n    ],\n    'Mobile Application Issue': [\n        'The mobile app was slow or had poor performance',\n        'A bug or error in the mobile app',\n        'The mobile app crashed or froze',\n        'The mobile app was difficult to use or understand',\n    ],\n    'Communication Channel Quality': [\n        'Poor audio quality, static, or bad phone connection',\n        'Loud background noise during a call',\n        'Issues with the live chat tool or functionality',\n        'Problems with email communication or response times',\n    ],\n\n    # --- Product Driven Category ---\n    'Feedback on the Product Itself': [\n        'The quality, a defect, or damage of the product',\n        'A suggestion or request for a new product feature',\n        'Feedback on the price, cost, or value for money',\n        'The design, appearance, or general ease of use of the product',\n    ]\n}\n\nprint(\"✅ Setup complete. All libraries and models are ready.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 2: Data Loading, Cleaning, and Sentiment Analysis\n**This cell prepares your core DataFrame by loading, cleaning, and running sentiment analysis.**","metadata":{}},{"cell_type":"code","source":"# # --- 1. Load Data Safely ---\n# # This block will attempt to load your file. If it fails, it will print an error and stop.\n# try:\n#     df = pd.read_excel(FILE_PATH)\n#     print(f\"✅ Successfully loaded {len(df)} rows from '{FILE_PATH}'.\")\n    \n#     # --- 2. Text Cleaning ---\n#     stop_words = set(stopwords.words('english')).union(CUSTOM_STOP_WORDS)\n#     lemmatizer = WordNetLemmatizer()\n#     def clean_text(text):\n#         if not isinstance(text, str): return \"\"\n#         text = text.lower()\n#         text = re.sub(r'[\\d\\n]', '', text)\n#         text = text.translate(str.maketrans('', '', string.punctuation))\n#         tokens = word_tokenize(text.strip())\n#         cleaned_tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words and len(w) > 2]\n#         return \" \".join(cleaned_tokens)\n    \n#     df.dropna(subset=[TEXT_COLUMN_NAME], inplace=True)\n#     df['cleaned_text'] = df[TEXT_COLUMN_NAME].apply(clean_text)\n    \n#     # --- 3. Sentiment Analysis ---\n#     sia = SentimentIntensityAnalyzer()\n#     df['sentiment_compound'] = df[TEXT_COLUMN_NAME].apply(lambda x: sia.polarity_scores(x)['compound'])\n#     def categorize_sentiment(compound):\n#         if compound >= 0.05: return 'Positive'\n#         if compound <= -0.05: return 'Negative'\n#         return 'Neutral'\n#     df['sentiment_label'] = df['sentiment_compound'].apply(categorize_sentiment)\n\n#     print(\"\\n--- Data Preview with Cleaned Text and Sentiment ---\")\n#     display(df[[TEXT_COLUMN_NAME, 'cleaned_text', 'sentiment_label']].head())\n\n#     # --- 4. Plot Sentiment Distribution and Save ---\n#     plt.figure(figsize=(6, 4))\n#     df['sentiment_label'].value_counts().plot(kind='bar', color=['green', 'red', 'grey'])\n#     plt.title('Sentiment Distribution')\n#     plt.ylabel('Number of Responses')\n#     plt.xticks(rotation=0)\n#     plt.savefig(os.path.join(OUTPUT_FOLDER_PATH, 'sentiment_distribution.png'), bbox_inches='tight')\n#     plt.show()\n\n# except FileNotFoundError:\n#     print(\"=\"*80)\n#     print(f\"❌ FATAL ERROR: File not found at the specified path.\")\n#     print(f\"   Your specified path: '{FILE_PATH}'\")\n#     print(\"   Please check the 'FILE_PATH' variable in your configuration cell and try again.\")\n#     print(\"=\"*80)\n#     # Raising the error stops the notebook execution\n#     raise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Revised 2.1","metadata":{}},{"cell_type":"code","source":"# --- 1. Load Data Safely ---\n# This block will attempt to load your file. If it fails, it will print an error and stop.\ntry:\n    df = pd.read_excel(FILE_PATH)\n    print(f\"✅ Successfully loaded {len(df)} rows from '{FILE_PATH}'.\")\n\n    # --- 2. Text Cleaning (UPGRADED) ---\n    # Import new libraries\n    from textblob import TextBlob\n    \n    stop_words = set(stopwords.words('english')).union(CUSTOM_STOP_WORDS)\n    lemmatizer = WordNetLemmatizer()\n    \n    def clean_text(text):\n        if not isinstance(text, str) or len(text.strip()) < 1: \n            return \"\"\n\n        # ✨ STEP 1: Translate non-English text to English\n        # Create a TextBlob object\n        blob = TextBlob(text)\n        # Detect language and translate if not English ('en')\n        if blob.detect_language() != 'en':\n            text = str(blob.translate(to='en'))\n\n        # ✨ STEP 2: Correct spelling\n        # Note: This step can be slow on large datasets\n        text = str(TextBlob(text).correct())\n        \n        # --- Original cleaning steps ---\n        text = text.lower()\n        text = re.sub(r'[\\d\\n]', '', text)\n        text = text.translate(str.maketrans('', '', string.punctuation))\n        tokens = word_tokenize(text.strip())\n        cleaned_tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words and len(w) > 2]\n        return \" \".join(cleaned_tokens)\n    \n    df.dropna(subset=[TEXT_COLUMN_NAME], inplace=True)\n    # Apply the new and improved function\n    df['cleaned_text'] = df[TEXT_COLUMN_NAME].progress_apply(clean_text) # Using progress_apply is good for slow functions\n    \n    # ... (The rest of your code for sentiment analysis and plotting remains the same) ...\n\n    # --- 3. Sentiment Analysis ---\n    sia = SentimentIntensityAnalyzer()\n    df['sentiment_compound'] = df[TEXT_COLUMN_NAME].apply(lambda x: sia.polarity_scores(x)['compound'])\n    def categorize_sentiment(compound):\n        if compound >= 0.05: return 'Positive'\n        if compound <= -0.05: return 'Negative'\n        return 'Neutral'\n    df['sentiment_label'] = df['sentiment_compound'].apply(categorize_sentiment)\n\n    print(\"\\n--- Data Preview with Cleaned Text and Sentiment ---\")\n    display(df[[TEXT_COLUMN_NAME, 'cleaned_text', 'sentiment_label']].head())\n\n    # --- 4. Plot Sentiment Distribution and Save ---\n    plt.figure(figsize=(6, 4))\n    df['sentiment_label'].value_counts().plot(kind='bar', color=['green', 'red', 'grey'])\n    plt.title('Sentiment Distribution')\n    plt.ylabel('Number of Responses')\n    plt.xticks(rotation=0)\n    plt.savefig(os.path.join(OUTPUT_FOLDER_PATH, 'sentiment_distribution.png'), bbox_inches='tight')\n    plt.show()\n\nexcept FileNotFoundError:\n    print(\"=\"*80)\n    print(f\"❌ FATAL ERROR: File not found at the specified path.\")\n    print(f\"    Your specified path: '{FILE_PATH}'\")\n    print(\"    Please check the 'FILE_PATH' variable in your configuration cell and try again.\")\n    print(\"=\"*80)\n    # Raising the error stops the notebook execution\n    raise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 3: Topic Evaluation (Silhouette & Coherence)","metadata":{}},{"cell_type":"code","source":"# ==============================================================================\n#  AUTOMATED TOPIC MODEL EVALUATION (Corrected and Complete)\n# ==============================================================================\nfrom sklearn.metrics import silhouette_score\nfrom gensim.corpora.dictionary import Dictionary\nfrom gensim.models.coherencemodel import CoherenceModel\nfrom gensim.models.ldamodel import LdaModel\nimport numpy as np\n\n# --- 1. Prepare Data for Evaluation ---\neval_vectorizer = CountVectorizer(max_df=0.9, min_df=5, stop_words='english')\ndtm_eval = eval_vectorizer.fit_transform(df['cleaned_text'].dropna())\ntexts_for_gensim = [word_tokenize(text) for text in df['cleaned_text'].dropna()]\ndictionary = Dictionary(texts_for_gensim)\ncorpus = [dictionary.doc2bow(text) for text in texts_for_gensim]\n\n# --- 2. Define a Range of Topics to Test ---\nmin_topics = 2\nmax_topics = 11\ntopic_range = range(min_topics, max_topics)\n\n# --- 3. Calculate Scores for Each Number of Topics ---\nsilhouette_scores = []\ncoherence_scores = []\nprint(\"Evaluating optimal number of topics (k). This may take several minutes...\")\nfor k in topic_range:\n    # Silhouette Score\n    lda_sklearn = LatentDirichletAllocation(n_components=k, random_state=42)\n    lda_sklearn.fit(dtm_eval)\n    if len(np.unique(lda_sklearn.transform(dtm_eval).argmax(axis=1))) > 1:\n        score = silhouette_score(dtm_eval, lda_sklearn.transform(dtm_eval).argmax(axis=1))\n        silhouette_scores.append(score)\n    else:\n        silhouette_scores.append(-1)\n    \n    # Coherence Score\n    lda_gensim = LdaModel(corpus=corpus, id2word=dictionary, num_topics=k, random_state=42)\n    coherence_model = CoherenceModel(model=lda_gensim, texts=texts_for_gensim, dictionary=dictionary, coherence='c_v')\n    coherence = coherence_model.get_coherence()\n    coherence_scores.append(coherence)\n    print(f\"  - Processed k={k} topics...\")\n\n# --- 4. Find the Optimal Number of Topics ---\n# Handle cases with no variance in scores to prevent errors\ns_range = np.max(silhouette_scores) - np.min(silhouette_scores)\nc_range = np.max(coherence_scores) - np.min(coherence_scores)\nnorm_silhouette = (silhouette_scores - np.min(silhouette_scores)) / s_range if s_range > 0 else np.zeros(len(silhouette_scores))\nnorm_coherence = (coherence_scores - np.min(coherence_scores)) / c_range if c_range > 0 else np.zeros(len(coherence_scores))\ncombined_score = norm_silhouette + norm_coherence\nbest_k_index = np.argmax(combined_score)\nrecommended_k = topic_range[best_k_index]\n\n# --- 5. Plot and Save the Results ---\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n# Plot Silhouette\nax1.plot(topic_range, silhouette_scores, marker='o', color='b')\nax1.set_title('Silhouette Score vs. Number of Topics')\nax1.axvline(x=recommended_k, color='grey', linestyle='--', label=f'Recommended k={recommended_k}')\nax1.legend()\n# Plot Coherence\nax2.plot(topic_range, coherence_scores, marker='o', color='r')\nax2.set_title('Topic Coherence (C_v) vs. Number of Topics')\nax2.axvline(x=recommended_k, color='grey', linestyle='--', label=f'Recommended k={recommended_k}')\nax2.legend()\nplt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_FOLDER_PATH, 'topic_evaluation_charts.png'), bbox_inches='tight')\nplt.show()\n\n# --- 6. Store Results and Update Variable ---\nevaluation_results = {\n    'Num_Topics (k)': list(topic_range),\n    'Silhouette_Score': silhouette_scores,\n    'Coherence_Score': coherence_scores\n}\ndf_topic_evaluation = pd.DataFrame(evaluation_results)\n\n# --- 7. Print Summary and Update TOPIC_MODEL_TOPICS Variable ---\nprint(\"\\n--- Evaluation Results Table ---\")\ndisplay(df_topic_evaluation.round(3))\n\nprint(\"\\n--- Automated Recommendation ---\")\nprint(f\"Best Silhouette Score at k = {topic_range[np.argmax(silhouette_scores)]}\")\nprint(f\"Best Coherence Score at k = {topic_range[np.argmax(coherence_scores)]}\")\nprint(\"-\" * 30)\nprint(f\"🏆 Recommended number of topics (best combined score): {recommended_k}\")\nprint(\"-\" * 30)\n\nTOPIC_MODEL_TOPICS = recommended_k\nprint(f\"✅ The 'TOPIC_MODEL_TOPICS' variable has been automatically set to {TOPIC_MODEL_TOPICS}.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 4: Exploratory Analysis (Frequency, N-grams, Word Clouds)\n**This cell prepares frequency tables and word cloud images for the final report.**","metadata":{}},{"cell_type":"code","source":"# --- 1. Prepare Overall Text and Tokens ---\nall_cleaned_text = \" \".join(df['cleaned_text'])\nall_tokens = word_tokenize(all_cleaned_text)\n\n# --- 2. Create and Store Frequency Tables ---\nfdist = FreqDist(all_tokens)\ndf_top_words = pd.DataFrame(fdist.most_common(20), columns=['Word', 'Frequency'])\n\nbigram_fdist = FreqDist(list(bigrams(all_tokens)))\n# CORRECTED: Provide both the bigram and its frequency to the DataFrame\ndf_top_bigrams = pd.DataFrame([(' '.join(gram), freq) for gram, freq in bigram_fdist.most_common(10)], columns=['Bigram', 'Frequency'])\n\ntrigram_fdist = FreqDist(list(trigrams(all_tokens)))\n# CORRECTED: Provide both the trigram and its frequency to the DataFrame\ndf_top_trigrams = pd.DataFrame([(' '.join(gram), freq) for gram, freq in trigram_fdist.most_common(10)], columns=['Trigram', 'Frequency'])\n\nprint(\"--- Top 20 Most Common Words ---\")\ndisplay(df_top_words)\n\nprint(\"--- Top 10 Most Common Bigrams ---\")\ndisplay(df_top_bigrams)\n\nprint(\"--- Top 10 Most Common Trigrams ---\")\ndisplay(df_top_trigrams)\n\n# --- 3. Generate and Save Word Clouds ---\ndef generate_and_save_wordcloud(text, title, filename):\n    if not text.strip():\n        print(f\"Skipping '{title}' word cloud: No text available.\")\n        return\n    wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate(text)\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title(title)\n    plt.savefig(os.path.join(OUTPUT_FOLDER_PATH, filename), bbox_inches='tight')\n    plt.show()\n\ngenerate_and_save_wordcloud(all_cleaned_text, 'Word Cloud (All Feedback)', 'wordcloud_all.png')\ngenerate_and_save_wordcloud(\" \".join(df[df.sentiment_label == 'Positive']['cleaned_text']), 'Word Cloud (Positive)', 'wordcloud_positive.png')\ngenerate_and_save_wordcloud(\" \".join(df[df.sentiment_label == 'Negative']['cleaned_text']), 'Word Cloud (Negative)', 'wordcloud_negative.png')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 5: Thematic Analysis (Topic Modeling and Zero-Shot Categorization)\n**This cell performs the main \"what are they talking about?\" analyses.**","metadata":{}},{"cell_type":"code","source":"# --- 1. Topic Modeling (LDA) ---\nprint(\"\\n--- Discovering Latent Topics (LDA) ---\")\nvectorizer = CountVectorizer(max_df=0.9, min_df=3, stop_words='english')\ndtm = vectorizer.fit_transform(df['cleaned_text'].dropna())\nif dtm.shape[0] > 1 and dtm.shape[1] > 1:\n    lda = LatentDirichletAllocation(n_components=TOPIC_MODEL_TOPICS, random_state=42)\n    lda.fit(dtm)\n    topic_results = []\n    feature_names = vectorizer.get_feature_names_out()\n    for topic_idx, topic in enumerate(lda.components_):\n        top_words_str = \", \".join([feature_names[i] for i in topic.argsort()[:-10 - 1:-1]])\n        topic_results.append([f\"Topic #{topic_idx + 1}\", top_words_str])\n    df_topics = pd.DataFrame(topic_results, columns=['Discovered Topic', 'Top Words'])\n    display(df_topics)\nelse:\n    print(\"Not enough data to perform topic modeling.\")\n    df_topics = pd.DataFrame() # Create empty df if it fails\n\n# --- 2. Zero-Shot Root Cause Categorization ---\nprint(\"\\n--- Loading Zero-Shot Classification model ---\")\nclassifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n\ndef get_multi_label_predictions(text, labels, threshold):\n    if not text or not isinstance(text, str): return []\n    results = classifier(text, candidate_labels=labels, multi_label=True)\n    return [label for i, label in enumerate(results['labels']) if results['scores'][i] >= threshold]\n\ndef extract_key_phrases(text):\n    return \"|\".join([str(p) for p in TextBlob(text).noun_phrases[:3]]) if text else \"\"\n\ndef categorize_row(row):\n    text = row[TEXT_COLUMN_NAME]\n    matched_cats = get_multi_label_predictions(text, list(CATEGORIES.keys()), CLASSIFICATION_THRESHOLD)\n    matched_subcats = []\n    if matched_cats:\n        for cat in matched_cats:\n            sub_preds = get_multi_label_predictions(text, CATEGORIES.get(cat, []), CLASSIFICATION_THRESHOLD)\n            matched_subcats.extend(sub_preds)\n        if not matched_subcats and (key_phrases := extract_key_phrases(text)):\n            matched_subcats.append(f\"SUGGESTION: {key_phrases}\")\n    return \"|\".join(matched_cats) if matched_cats else 'Uncategorized', \"|\".join(matched_subcats) if matched_subcats else \"\"\n\nprint(f\"\\n--- Starting Zero-Shot categorization with a threshold of {CLASSIFICATION_THRESHOLD:.2f} ---\")\ndf[['Category', 'Sub-Category']] = df.progress_apply(categorize_row, axis=1, result_type='expand')\n\nprint(\"\\n--- Categorization Complete ---\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 6: Deep-Dive Categorization Analysis\n**This cell is dedicated to analyzing the results of our categorization, creating the tables and charts needed for the executive summary.**","metadata":{}},{"cell_type":"code","source":"# ==============================================================================\n# 6. DEEP-DIVE CATEGORIZATION ANALYSIS (REVISED)\n# ==============================================================================\n\n# --- 1. Create Exploded DataFrames (for re-use) ---\n# Create these once to avoid re-computing them, improving efficiency.\ndf_exploded_cat = df.assign(Category=df['Category'].str.split('|')).explode('Category')\n\n# --- FIX: Explicitly split and explode the correct 'Sub-Category' column ---\n# This ensures we get counts of individual sub-categories, not combined strings.\ndf_exploded_subcat = df.copy()\ndf_exploded_subcat['Sub-Category'] = df_exploded_subcat['Sub-Category'].str.split('|')\ndf_exploded_subcat = df_exploded_subcat.explode('Sub-Category')\n# --- END FIX ---\n\ndf_exploded_subcat.dropna(subset=['Sub-Category'], inplace=True) # Drop rows where sub-category is now null\ndf_exploded_subcat = df_exploded_subcat[df_exploded_subcat['Sub-Category'].str.strip() != ''] # Remove empty strings\n\n# --- 2. Categorization Summary ---\ntotal_rows = len(df)\nuncategorized_count = len(df[df['Category'] == 'Uncategorized'])\ncategorized_count = total_rows - uncategorized_count\ncategorization_rate = (categorized_count / total_rows) * 100 if total_rows > 0 else 0\nprint(\"\\n--- Categorization Summary ---\")\nsummary_metrics = {\n    'Metric': ['Total Verbatims', 'Categorized', 'Uncategorized', 'Categorization Rate'],\n    'Value': [total_rows, categorized_count, uncategorized_count, f\"{categorization_rate:.2f}%\"]\n}\ndf_summary_metrics = pd.DataFrame(summary_metrics)\ndisplay(df_summary_metrics)\n\n# --- 3. Sentiment Breakdown Tables ---\nprint(\"\\n--- Sentiment Breakdown by Category ---\")\ndf_sentiment_by_cat = pd.crosstab(df_exploded_cat['Category'], df_exploded_cat['sentiment_label'])\ndf_sentiment_by_cat['Total'] = df_sentiment_by_cat.sum(axis=1)\ndf_sentiment_by_cat.sort_values(by='Total', ascending=False, inplace=True)\ndisplay(df_sentiment_by_cat.drop(columns='Total'))\n\nprint(\"\\n--- Sentiment Breakdown by Sub-Category ---\")\n# This will now use the correctly exploded data\ndf_sentiment_by_subcat = pd.crosstab(df_exploded_subcat['Sub-Category'], df_exploded_subcat['sentiment_label'])\ndf_sentiment_by_subcat['Total'] = df_sentiment_by_subcat.sum(axis=1)\ndf_sentiment_by_subcat.sort_values(by='Total', ascending=False, inplace=True)\ndisplay(df_sentiment_by_subcat.drop(columns='Total'))\n\n# --- 4. Top Keywords for \"Uncategorized\" Verbatims ---\nprint(\"\\n--- Top Keywords in Uncategorized Verbatims ---\")\nuncategorized_text = \" \".join(df[df['Category'] == 'Uncategorized']['cleaned_text'])\nif uncategorized_text.strip():\n    uncategorized_fdist = FreqDist(word_tokenize(uncategorized_text))\n    df_uncategorized_keywords = pd.DataFrame(uncategorized_fdist.most_common(20), columns=['Keyword', 'Frequency'])\n    display(df_uncategorized_keywords.head(10))\nelse:\n    print(\"No keywords to display for uncategorized verbatims.\")\n    df_uncategorized_keywords = pd.DataFrame(columns=['Keyword', 'Frequency'])\n\n# --- 5. Category and Sub-Category Frequency Analysis & Visualization ---\ndef plot_and_save_top_n(series, title, filename, n=15):\n    \"\"\"Helper function to plot and save frequency charts.\"\"\"\n    if series.empty:\n        print(f\"Skipping plot '{title}': No data.\")\n        return\n    plt.figure(figsize=(12, 8)) \n    series.head(n).sort_values(ascending=True).plot(kind='barh', color='skyblue')\n    plt.title(title)\n    plt.xlabel('Count')\n    plt.subplots_adjust(left=0.4) \n    plt.savefig(os.path.join(OUTPUT_FOLDER_PATH, filename), bbox_inches='tight')\n    plt.show()\n\n# --- Calculate Overall Frequencies ---\nprint(\"\\n--- Calculating and Plotting Overall Frequencies ---\")\ndf_cat_counts = df_exploded_cat['Category'].value_counts()\n# This will now use the correctly exploded data\ndf_subcat_counts = df_exploded_subcat['Sub-Category'].value_counts()\n\nplot_and_save_top_n(df_cat_counts.drop('Uncategorized', errors='ignore'), 'Overall Top Categories', 'freq_cat_overall.png')\nplot_and_save_top_n(df_subcat_counts, 'Overall Top Sub-Categories', 'freq_subcat_overall.png')\n\n# --- Calculate Frequencies Split by Sentiment ---\nprint(\"\\n--- Calculating and Plotting Frequencies by Sentiment ---\")\nfor sentiment in ['Positive', 'Negative', 'Neutral']:\n    df_sentiment_exploded_cat = df_exploded_cat[df_exploded_cat['sentiment_label'] == sentiment]\n    if not df_sentiment_exploded_cat.empty:\n        cat_counts = df_sentiment_exploded_cat['Category'].value_counts()\n        plot_and_save_top_n(cat_counts, f'Top Categories ({sentiment} Sentiment)', f'freq_cat_{sentiment.lower()}.png')\n\n    df_sentiment_exploded_subcat = df_exploded_subcat[df_exploded_subcat['sentiment_label'] == sentiment]\n    if not df_sentiment_exploded_subcat.empty:\n        subcat_counts = df_sentiment_exploded_subcat['Sub-Category'].value_counts()\n        plot_and_save_top_n(subcat_counts, f'Top Sub-Categories ({sentiment} Sentiment)', f'freq_subcat_{sentiment.lower()}.png')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 7: Similarity Analysis (Jaccard & Semantic)\n**This cell performs the deeper analysis on vocabulary overlap and semantic relationships.**","metadata":{}},{"cell_type":"code","source":"# --- 1. Jaccard Similarity Between Sentiments ---\ndef get_top_ngrams(tokens, n, N_top):\n    \"\"\"Extracts the top N n-grams from a list of tokens.\"\"\"\n    ngrams_list = tokens if n == 1 else list(nltk.ngrams(tokens, n))\n    return [item for item, freq in FreqDist(ngrams_list).most_common(N_top)]\n\ndef jaccard_similarity(list1, list2):\n    \"\"\"Calculates Jaccard similarity between two lists.\"\"\"\n    set1, set2 = set(list1), set(list2)\n    intersection_len = len(set1.intersection(set2))\n    union_len = len(set1.union(set2))\n    return intersection_len / union_len if union_len > 0 else 0.0\n\n# Calculate Jaccard similarity for top words and bigrams between sentiments\nsentiments = ['Positive', 'Negative', 'Neutral']\ntokens_by_sentiment = {s: word_tokenize(\" \".join(df[df.sentiment_label == s]['cleaned_text'])) for s in sentiments}\ncomparisons = [(\"Positive\", \"Negative\"), (\"Positive\", \"Neutral\"), (\"Negative\", \"Neutral\")]\n\nresults = {\n    \"Comparison\": [f\"{s1} vs. {s2}\" for s1, s2 in comparisons],\n    \"Words (Top 20)\": [jaccard_similarity(get_top_ngrams(tokens_by_sentiment[s1], 1, 20), get_top_ngrams(tokens_by_sentiment[s2], 1, 20)) for s1, s2 in comparisons],\n    \"Bigrams (Top 10)\": [jaccard_similarity(get_top_ngrams(tokens_by_sentiment[s1], 2, 10), get_top_ngrams(tokens_by_sentiment[s2], 2, 10)) for s1, s2 in comparisons],\n    \"Trigrams (Top 10)\": [jaccard_similarity(get_top_ngrams(tokens_by_sentiment[s1], 3, 10), get_top_ngrams(tokens_by_sentiment[s2], 3, 10)) for s1, s2 in comparisons],\n}\nsimilarity_df = pd.DataFrame(results)\n\n# --- 2. Inter-Item Semantic & Jaccard Similarity ---\nnlp = spacy.load(\"en_core_web_md\")\ntop_words_overall = get_top_ngrams(all_tokens, 1, 20) # Top 20 Words\ntop_bigrams_overall = get_top_ngrams(all_tokens, 2, 10) # Top 10 Bigrams\ntop_trigrams_overall = get_top_ngrams(all_tokens, 3, 10) # Top 10 Trigrams\n\n# Word vs Word (Semantic Similarity)\nmatrix_words = np.array([[nlp(w1).similarity(nlp(w2)) for w2 in top_words_overall] for w1 in top_words_overall])\nsimilarity_df_words = pd.DataFrame(matrix_words, index=top_words_overall, columns=top_words_overall)\n\n# Words vs Bigrams (Jaccard Similarity)\nmatrix_words_vs_bigrams = np.array([[jaccard_similarity([word], list(bigram)) for bigram in top_bigrams_overall] for word in top_words_overall])\nsimilarity_df_words_vs_bigrams = pd.DataFrame(matrix_words_vs_bigrams, index=top_words_overall, columns=[' '.join(g) for g in top_bigrams_overall])\n\n# Words vs Trigrams (Jaccard Similarity)\nmatrix_words_vs_trigrams = np.array([[jaccard_similarity([word], list(trigram)) for trigram in top_trigrams_overall] for word in top_words_overall])\nsimilarity_df_words_vs_trigrams = pd.DataFrame(matrix_words_vs_trigrams, index=top_words_overall, columns=[' '.join(g) for g in top_trigrams_overall])\n\n# Bigram vs Bigram (Jaccard Similarity)\nmatrix_bg = np.array([[jaccard_similarity(list(g1), list(g2)) for g2 in top_bigrams_overall] for g1 in top_bigrams_overall])\nsimilarity_df_bigrams = pd.DataFrame(matrix_bg, index=[' '.join(g) for g in top_bigrams_overall], columns=[' '.join(g) for g in top_bigrams_overall])\n\n# Trigram vs Trigram (Jaccard Similarity)\nmatrix_tg = np.array([[jaccard_similarity(list(g1), list(g2)) for g2 in top_trigrams_overall] for g1 in top_trigrams_overall])\nsimilarity_df_trigrams = pd.DataFrame(matrix_tg, index=[' '.join(g) for g in top_trigrams_overall], columns=[' '.join(g) for g in top_trigrams_overall])\n\n\n# --- 3. Generate and Save Heatmap Images ---\ndef create_and_save_heatmap(df_plot, title, filename, annot=False, cmap='viridis', figsize=(12, 10)):\n    \"\"\"Creates, displays, and saves a heatmap from a DataFrame.\"\"\"\n    plt.figure(figsize=figsize)\n    sns.heatmap(df_plot, annot=annot, cmap=cmap, fmt=\".2f\")\n    plt.title(title, fontsize=16)\n    plt.savefig(os.path.join(OUTPUT_FOLDER_PATH, filename), bbox_inches='tight')\n    plt.show()\n\n# Generate and save the heatmaps\ncreate_and_save_heatmap(similarity_df_words, 'Semantic Similarity of Top 20 Words', 'heatmap_words.png')\ncreate_and_save_heatmap(similarity_df_bigrams, 'Jaccard Similarity of Top 10 Bigrams', 'heatmap_bigrams.png', annot=True, cmap='coolwarm')\n\n# ADDED: Heatmap for Trigrams vs Trigrams\ncreate_and_save_heatmap(similarity_df_trigrams, 'Jaccard Similarity of Top 10 Trigrams', 'heatmap_trigrams.png', annot=True, cmap='coolwarm')\n\n# ADDED: Heatmap for Words vs Bigrams\ncreate_and_save_heatmap(similarity_df_words_vs_bigrams, 'Jaccard Similarity: Top Words vs. Top Bigrams', 'heatmap_words_vs_bigrams.png', annot=True, cmap='magma', figsize=(10, 12))\n\n# ADDED: Heatmap for Words vs Trigrams\ncreate_and_save_heatmap(similarity_df_words_vs_trigrams, 'Jaccard Similarity: Top Words vs. Top Trigrams', 'heatmap_words_vs_trigrams.png', annot=True, cmap='magma', figsize=(10, 12))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 8: Final Report Generation\n**This final cell gathers every DataFrame and image and compiles them into a single, multi-sheet Excel report.**","metadata":{}},{"cell_type":"code","source":"# ==============================================================================\n# 8. FINAL REPORT GENERATION (FINAL, ROBUST VERSION)\n# ==============================================================================\n# Make sure to have this import for adding images\nfrom openpyxl.drawing.image import Image\nimport pandas as pd\nimport os\nfrom datetime import datetime\n\n# --- 0. Helper Function to Add Images ---\n# This helper function simplifies adding images by checking if the file exists first.\ndef add_image_if_exists(worksheet, image_filename, cell_anchor, folder_path):\n    \"\"\"Checks for an image file and adds it to the specified worksheet cell.\"\"\"\n    image_path = os.path.join(folder_path, image_filename)\n    if os.path.exists(image_path):\n        img = Image(image_path)\n        worksheet.add_image(img, cell_anchor)\n    else:\n        print(f\"Warning: Image file not found at {image_path}, skipping.\")\n\n# --- 1. Generate Versioned Filename ---\ncurrent_date = datetime.now().strftime('%Y-%m-%d')\nbase_filename = f\"{current_date}_{PROGRAM_NAME}_{KPIS_IN_SCOPE}_{LOBS_IN_SCOPE}_Verbatim_Analysis\"\nminor_version = 0\nwhile True:\n    version_str = f\"v{MAJOR_VERSION:02d}.{minor_version:02d}\"\n    output_filename = f\"{base_filename}_{version_str}.xlsx\"\n    full_path = os.path.join(OUTPUT_FOLDER_PATH, output_filename)\n    if not os.path.exists(full_path):\n        break\n    minor_version += 1\n\n# --- 2. Use ExcelWriter to save all results ---\nwith pd.ExcelWriter(full_path, engine='openpyxl') as writer:\n    print(f\"\\n--- 🚀 Writing to Excel file: {output_filename} ---\")\n\n    # --- Sheet 1: Executive Summary ---\n    print(\"Writing Sheet: Executive_Summary\")\n    row_offset = 0\n    df_summary_metrics.to_excel(writer, sheet_name='Executive_Summary', index=False, startrow=row_offset + 1)\n    pos1 = row_offset + len(df_summary_metrics) + 3\n    \n    df_topic_evaluation.round(3).to_excel(writer, sheet_name='Executive_Summary', index=False, startrow=pos1 + 1)\n    pos2 = pos1 + len(df_topic_evaluation) + 3\n\n    df_cat_counts.to_frame(name='Count').to_excel(writer, sheet_name='Executive_Summary', startrow=pos2 + 1)\n    pos3 = pos2 + len(df_cat_counts) + 3\n\n    df_subcat_counts.to_frame(name='Count').to_excel(writer, sheet_name='Executive_Summary', startrow=pos3 + 1)\n\n    ws_summary = writer.sheets['Executive_Summary']\n    ws_summary.cell(row=row_offset + 1, column=1, value=\"Categorization Summary\")\n    ws_summary.cell(row=pos1 + 1, column=1, value=\"Topic Model Evaluation (Silhouette & Coherence)\")\n    ws_summary.cell(row=pos2 + 1, column=1, value=\"Overall Category Counts\")\n    ws_summary.cell(row=pos3 + 1, column=1, value=\"Overall Sub-Category Counts\")\n\n    add_image_if_exists(ws_summary, 'topic_evaluation_charts.png', 'E2', OUTPUT_FOLDER_PATH)\n    add_image_if_exists(ws_summary, 'freq_cat_overall.png', f'E{pos2 + 2}', OUTPUT_FOLDER_PATH)\n    add_image_if_exists(ws_summary, 'freq_subcat_overall.png', f'E{pos3 + 2}', OUTPUT_FOLDER_PATH)\n\n    # --- Sheet 2: Categorization Results (Full Data) ---\n    print(\"Writing Sheet: Categorization_Results\")\n    df.to_excel(writer, sheet_name='Categorization_Results', index=False)\n\n    # --- Sheet 3: Sentiment Analysis ---\n    print(\"Writing Sheet: Sentiment_Analysis\")\n    row_offset = 0\n    df_sentiment_by_cat.to_excel(writer, sheet_name='Sentiment_Analysis', startrow=row_offset + 1)\n    pos1 = row_offset + len(df_sentiment_by_cat) + 3\n    df_sentiment_by_subcat.to_excel(writer, sheet_name='Sentiment_Analysis', startrow=pos1 + 1)\n    \n    ws_sentiment = writer.sheets['Sentiment_Analysis']\n    ws_sentiment.cell(row=row_offset + 1, column=1, value=\"Sentiment Breakdown by Category\")\n    ws_sentiment.cell(row=pos1 + 1, column=1, value=\"Sentiment Breakdown by Sub-Category\")\n    add_image_if_exists(ws_sentiment, 'sentiment_distribution.png', 'G2', OUTPUT_FOLDER_PATH)\n\n    charts_start_row = pos1 + len(df_sentiment_by_subcat) + 5\n    sentiment_charts = [\n        ('Positive Sentiment', 'freq_cat_positive.png', 'freq_subcat_positive.png'),\n        ('Negative Sentiment', 'freq_cat_negative.png', 'freq_subcat_negative.png'),\n        ('Neutral Sentiment', 'freq_cat_neutral.png', 'freq_subcat_neutral.png')\n    ]\n    current_row = charts_start_row\n    for title, cat_chart, subcat_chart in sentiment_charts:\n        ws_sentiment.cell(row=current_row, column=1, value=title)\n        add_image_if_exists(ws_sentiment, cat_chart, f'A{current_row + 1}', OUTPUT_FOLDER_PATH)\n        add_image_if_exists(ws_sentiment, subcat_chart, f'K{current_row + 1}', OUTPUT_FOLDER_PATH)\n        current_row += 40\n\n    # --- Sheet 4: Exploratory Analysis (N-Grams & Word Clouds) ---\n    print(\"Writing Sheet: Exploratory_Analysis\")\n    row_offset = 0\n    df_top_words.to_excel(writer, sheet_name='Exploratory_Analysis', index=False, startrow=row_offset + 1)\n    pos1 = row_offset + len(df_top_words) + 3\n    df_top_bigrams.to_excel(writer, sheet_name='Exploratory_Analysis', index=False, startrow=pos1 + 1)\n    pos2 = pos1 + len(df_top_bigrams) + 3\n    df_top_trigrams.to_excel(writer, sheet_name='Exploratory_Analysis', index=False, startrow=pos2 + 1)\n\n    ws_exploratory = writer.sheets['Exploratory_Analysis']\n    ws_exploratory.cell(row=row_offset + 1, column=1, value=\"Top 20 Words\")\n    ws_exploratory.cell(row=pos1 + 1, column=1, value=\"Top 10 Bigrams\")\n    ws_exploratory.cell(row=pos2 + 1, column=1, value=\"Top 10 Trigrams\")\n    \n    add_image_if_exists(ws_exploratory, 'wordcloud_all.png', 'E2', OUTPUT_FOLDER_PATH)\n    add_image_if_exists(ws_exploratory, 'wordcloud_positive.png', 'E25', OUTPUT_FOLDER_PATH)\n    add_image_if_exists(ws_exploratory, 'wordcloud_negative.png', 'E50', OUTPUT_FOLDER_PATH)\n\n    # --- Sheet 5: Topic Modeling & Uncategorized ---\n    print(\"Writing Sheet: Topic_Modeling_Deep_Dive\")\n    row_offset = 0\n    df_topics.to_excel(writer, sheet_name='Topic_Modeling_Deep_Dive', index=False, startrow=row_offset+1)\n    pos1 = row_offset + len(df_topics) + 3\n    df_uncategorized_keywords.to_excel(writer, sheet_name='Topic_Modeling_Deep_Dive', index=False, startrow=pos1 + 1)\n    \n    ws_topics = writer.sheets['Topic_Modeling_Deep_Dive']\n    ws_topics.cell(row=row_offset + 1, column=1, value=\"Discovered Topics (LDA)\")\n    ws_topics.cell(row=pos1 + 1, column=1, value=\"Top Keywords in Uncategorized Verbatims\")\n\n    # --- Sheet 6: Similarity Analysis (REVISED) ---\n    print(\"Writing Sheet: Similarity_Analysis\")\n    \n    # Write Jaccard Similarity table\n    similarity_df.to_excel(writer, sheet_name='Similarity_Analysis', index=False, startrow=1)\n    ws_similarity = writer.sheets['Similarity_Analysis']\n    ws_similarity.cell(row=1, column=1, value=\"Jaccard Similarity Between Sentiments\")\n    \n    # Position for the first heatmap\n    current_row = len(similarity_df) + 5\n    \n    # Add heatmaps with titles\n    ws_similarity.cell(row=current_row, column=1, value=\"Semantic Similarity of Top 20 Words\")\n    add_image_if_exists(ws_similarity, 'heatmap_words.png', f'A{current_row + 1}', OUTPUT_FOLDER_PATH)\n    \n    ws_similarity.cell(row=current_row, column=15, value=\"Jaccard Similarity of Top 10 Bigrams\")\n    add_image_if_exists(ws_similarity, 'heatmap_bigrams.png', f'O{current_row + 1}', OUTPUT_FOLDER_PATH)\n    \n    # Move to the next row for more heatmaps\n    current_row += 55\n    \n    ws_similarity.cell(row=current_row, column=1, value=\"Jaccard Similarity of Top 10 Trigrams\")\n    add_image_if_exists(ws_similarity, 'heatmap_trigrams.png', f'A{current_row + 1}', OUTPUT_FOLDER_PATH)\n    \n    ws_similarity.cell(row=current_row, column=15, value=\"Jaccard Similarity: Top Words vs. Top Bigrams\")\n    add_image_if_exists(ws_similarity, 'heatmap_words_vs_bigrams.png', f'O{current_row + 1}', OUTPUT_FOLDER_PATH)\n    \n    current_row += 55\n    ws_similarity.cell(row=current_row, column=1, value=\"Jaccard Similarity: Top Words vs. Top Trigrams\")\n    add_image_if_exists(ws_similarity, 'heatmap_words_vs_trigrams.png', f'A{current_row + 1}', OUTPUT_FOLDER_PATH)\n\n\nprint(f\"\\n✅ All analysis results and plots have been saved to a multi-sheet file:\")\nprint(f\"   {full_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cell 9: Clear the /Kaggle/Working output directory","metadata":{}},{"cell_type":"code","source":"# # Ctrl + / to un/comment out code while highlighted\n\n# import os\n# import shutil\n\n# # This is the directory you want to clear\n# output_dir = '/kaggle/working/'\n\n# # Loop through everything in the directory\n# for filename in os.listdir(output_dir):\n#     file_path = os.path.join(output_dir, filename)\n#     try:\n#         # If it's a file or link, delete it\n#         if os.path.isfile(file_path) or os.path.islink(file_path):\n#             os.unlink(file_path)\n#         # If it's a directory, delete it and all its contents\n#         elif os.path.isdir(file_path):\n#             shutil.rmtree(file_path)\n#         print(f\"Deleted: {filename}\")\n#     except Exception as e:\n#         print(f'Failed to delete {file_path}. Reason: {e}')\n\n# print(\"\\n✅ Output directory has been cleared.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}