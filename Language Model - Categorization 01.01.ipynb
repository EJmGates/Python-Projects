{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e138aa-a96d-4c59-bb98-e03806407143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: openpyxl in c:\\programdata\\anaconda3\\lib\\site-packages (3.0.7)\n",
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.59.0)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "Requirement already satisfied: et-xmlfile in c:\\programdata\\anaconda3\\lib\\site-packages (from openpyxl) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2024.11.6)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (7.1.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.35.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from networkx->torch) (5.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n",
      "Requirement already satisfied: huggingface_hub[hf_xet] in c:\\programdata\\anaconda3\\lib\\site-packages (0.35.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (5.4.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.13.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (20.9)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (2025.3.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.59.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface_hub[hf_xet]) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (4.0.0)\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\EJG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\EJG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\EJG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\EJG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\EJG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\EJG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Zero-Shot Classification model...\n",
      "✅ Model loaded successfully.\n",
      "\n",
      "Successfully loaded 50 rows from 'D:/Z - Neverwonderland/2 - Prince Sarcawesum/1 - DESIGN/MEDIAWARE ARTS AND PRINTS/AAA_Corporate Material/Data Analysis/Verbatim Analysis/Dummy Verbatim Dataset.xlsx'.\n",
      "\n",
      "Starting categorization with a threshold of 0.60...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f2070e7adf43b29f30c2f850355125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Categorizing Verbatims:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Categorization Complete ---\n",
      "Result Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verbatim</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"The website was a mess, couldn't find the spe...</td>\n",
       "      <td>Interaction with Agent or Staff, Technical Sys...</td>\n",
       "      <td>Difficulty navigating or finding information o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"My new laptop overheated almost immediately a...</td>\n",
       "      <td>Interaction with Agent or Staff, Feedback on t...</td>\n",
       "      <td>The quality, a defect, or damage of the produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"I tried to use the live chat, but no one ever...</td>\n",
       "      <td>Interaction with Agent or Staff, Call Environm...</td>\n",
       "      <td>External factors outside of the agent's control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"The delivery was two days late and the box wa...</td>\n",
       "      <td>Interaction with Agent or Staff</td>\n",
       "      <td>SUGGESTION: hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"I returned a broken phone and haven't receive...</td>\n",
       "      <td>Interaction with Agent or Staff, Call Environm...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Verbatim  \\\n",
       "0  \"The website was a mess, couldn't find the spe...   \n",
       "1  \"My new laptop overheated almost immediately a...   \n",
       "2  \"I tried to use the live chat, but no one ever...   \n",
       "3  \"The delivery was two days late and the box wa...   \n",
       "4  \"I returned a broken phone and haven't receive...   \n",
       "\n",
       "                                            Category  \\\n",
       "0  Interaction with Agent or Staff, Technical Sys...   \n",
       "1  Interaction with Agent or Staff, Feedback on t...   \n",
       "2  Interaction with Agent or Staff, Call Environm...   \n",
       "3                    Interaction with Agent or Staff   \n",
       "4  Interaction with Agent or Staff, Call Environm...   \n",
       "\n",
       "                                        Sub-Category  \n",
       "0  Difficulty navigating or finding information o...  \n",
       "1  The quality, a defect, or damage of the produc...  \n",
       "2    External factors outside of the agent's control  \n",
       "3                                   SUGGESTION: hope  \n",
       "4                                                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Categorization Summary ---\n",
      "Total Verbatims Analyzed: 50\n",
      "Successfully Categorized:   47\n",
      "Uncategorized ('Blanks'):   3\n",
      "Categorization Rate:        94.00%\n",
      "\n",
      "✅ Successfully saved categorized results to:\n",
      "C:/Users/EJG/Documents/Analysis_Results\\2025-09-18_Program_1_KPI_LOB_Verbatim_Analysis_v01.03.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "#  SETUP: INSTALL AND IMPORT LIBRARIES\n",
    "# ==============================================================================\n",
    "# Installs all necessary libraries.\n",
    "!pip install pandas openpyxl transformers torch tqdm textblob\n",
    "!pip install huggingface_hub[hf_xet]\n",
    "!python -m textblob.download_corpora\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from transformers import pipeline\n",
    "from tqdm.auto import tqdm\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Register tqdm for use with pandas .progress_apply()\n",
    "tqdm.pandas(desc=\"Categorizing Verbatims\")\n",
    "\n",
    "# ==============================================================================\n",
    "#  🔴 USER CONFIGURATION 🔴\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Input File Details ---\n",
    "FILE_PATH = r'D:/Z - Neverwonderland/2 - Prince Sarcawesum/1 - DESIGN/MEDIAWARE ARTS AND PRINTS/AAA_Corporate Material/Data Analysis/Verbatim Analysis/Dummy Verbatim Dataset.xlsx'  # 👈 CHANGE THIS\n",
    "TEXT_COLUMN = 'Verbatim'   # 👈 CHANGE THIS\n",
    "\n",
    "# --- Output File Details ---\n",
    "OUTPUT_FOLDER_PATH = r'C:/Users/EJG/Documents/Analysis_Results' # 👈 Set your desired output folder\n",
    "PROGRAM_NAME = \"Program_1\"\n",
    "KPIS_IN_SCOPE = \"KPI\"\n",
    "LOBS_IN_SCOPE = \"LOB\"\n",
    "MAJOR_VERSION = 1\n",
    "\n",
    "# --- Classification Settings ---\n",
    "CLASSIFICATION_THRESHOLD = 0.60\n",
    "\n",
    "# --- Define Your Categories and Sub-Categories ---\n",
    "CATEGORIES = {\n",
    "    'Interaction with Agent or Staff': [\n",
    "        \"Agent's communication and listening skills\", \"Agent's knowledge and problem-solving ability\",\n",
    "        'Efficiency and speed of call handling', \"Attitude, empathy, and professionalism of the agent\",\n",
    "        \"Representative's sales skills or pressure\"\n",
    "    ],\n",
    "    'Company Process or Policy Issue': [\n",
    "        'Confusion or disagreement with a company policy', 'The resolution process was too complex or long',\n",
    "        'The time it took to resolve the issue', \"Problems with a follow-up or return contact\",\n",
    "        'Difficulty with the sign-up or onboarding process'\n",
    "    ],\n",
    "    'Technical System or Tool Problem': [\n",
    "        'A software bug, glitch, or error message', 'The system, app, or website was slow and unresponsive',\n",
    "        'The tool or software was difficult to use or understand', 'Difficulty navigating or finding information on the website',\n",
    "        'The application or website crashed or froze'\n",
    "    ],\n",
    "    'Feedback on the Product Itself': [\n",
    "        'The quality, a defect, or damage of the product', 'A suggestion or request for a new product feature',\n",
    "        'Feedback on the price, cost, or value for money', 'The design, appearance, or ease of use of the product',\n",
    "        'The product was out of stock or unavailable'\n",
    "    ],\n",
    "    'Call Environment or Connection Issue': [\n",
    "        'Loud background noise during the interaction', 'Poor audio quality, static, or a bad connection',\n",
    "        \"External factors outside of the agent's control\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "#  CORE LOGIC (No need to edit below this line)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Load the Zero-Shot Classification Model ---\n",
    "print(\"Loading Zero-Shot Classification model...\")\n",
    "try:\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "    print(\"✅ Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    classifier = None\n",
    "\n",
    "# --- 2. Load and Prepare Data ---\n",
    "try:\n",
    "    df = pd.read_excel(FILE_PATH)\n",
    "    print(f\"\\nSuccessfully loaded {len(df)} rows from '{FILE_PATH}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"⚠️ Warning: File not found. Loading dummy data.\")\n",
    "    df = pd.DataFrame({ TEXT_COLUMN: [\"The agent was knowledgeable, but the new billing statement is very confusing.\"] })\n",
    "\n",
    "df.dropna(subset=[TEXT_COLUMN], inplace=True)\n",
    "\n",
    "# --- 3. Define the Classification and Extraction Functions ---\n",
    "def get_multi_label_predictions(text, labels, threshold):\n",
    "    if not text or not isinstance(text, str): return []\n",
    "    results = classifier(text, candidate_labels=labels, multi_label=True)\n",
    "    return [label for i, label in enumerate(results['labels']) if results['scores'][i] >= threshold]\n",
    "\n",
    "def extract_key_phrases(text):\n",
    "    \"\"\"Extracts noun phrases from a text to suggest new sub-categories.\"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    # Join the noun phrases, limit to the first 3 for brevity\n",
    "    phrases = [phrase for phrase in blob.noun_phrases[:3]]\n",
    "    return \", \".join(phrases) if phrases else \"\"\n",
    "\n",
    "def categorize_row(row, text_column, category_map, threshold):\n",
    "    text = row[text_column]\n",
    "    main_categories = list(category_map.keys())\n",
    "    matched_categories = get_multi_label_predictions(text, main_categories, threshold)\n",
    "    \n",
    "    matched_subcategories = []\n",
    "    \n",
    "    if matched_categories:\n",
    "        for category in matched_categories:\n",
    "            sub_category_labels = category_map.get(category, [])\n",
    "            if sub_category_labels:\n",
    "                sub_preds = get_multi_label_predictions(text, sub_category_labels, threshold)\n",
    "                matched_subcategories.extend(sub_preds)\n",
    "        \n",
    "        # If a main category was found but NO sub-categories were, suggest new ones.\n",
    "        if not matched_subcategories:\n",
    "            key_phrases = extract_key_phrases(text)\n",
    "            if key_phrases:\n",
    "                matched_subcategories.append(f\"SUGGESTION: {key_phrases}\")\n",
    "\n",
    "    category_str = \", \".join(matched_categories) if matched_categories else \"Uncategorized\"\n",
    "    subcategory_str = \", \".join(matched_subcategories) if matched_subcategories else \"\"\n",
    "    return category_str, subcategory_str\n",
    "\n",
    "# --- 4. Apply Categorization to the DataFrame ---\n",
    "if classifier and not df.empty:\n",
    "    print(f\"\\nStarting categorization with a threshold of {CLASSIFICATION_THRESHOLD:.2f}...\")\n",
    "    df[['Category', 'Sub-Category']] = df.progress_apply(\n",
    "        lambda row: categorize_row(row, TEXT_COLUMN, CATEGORIES, CLASSIFICATION_THRESHOLD),\n",
    "        axis=1, result_type='expand'\n",
    "    )\n",
    "\n",
    "    # --- 5. Review, Summarize, and Save Results ---\n",
    "    print(\"\\n--- Categorization Complete ---\")\n",
    "    \n",
    "    # Feature: In-Notebook Preview of the results\n",
    "    print(\"Result Preview:\")\n",
    "    display(df[[TEXT_COLUMN, 'Category', 'Sub-Category']].head())\n",
    "    \n",
    "    # Feature: Count of blanks / uncategorized items\n",
    "    total_rows = len(df)\n",
    "    uncategorized_count = len(df[df['Category'] == 'Uncategorized'])\n",
    "    categorized_count = total_rows - uncategorized_count\n",
    "    categorization_rate = (categorized_count / total_rows) * 100 if total_rows > 0 else 0\n",
    "    \n",
    "    print(\"\\n--- Categorization Summary ---\")\n",
    "    print(f\"Total Verbatims Analyzed: {total_rows}\")\n",
    "    print(f\"Successfully Categorized:   {categorized_count}\")\n",
    "    print(f\"Uncategorized ('Blanks'):   {uncategorized_count}\")\n",
    "    print(f\"Categorization Rate:        {categorization_rate:.2f}%\")\n",
    "    \n",
    "    # Feature: Dynamic & Versioned Filename\n",
    "    os.makedirs(OUTPUT_FOLDER_PATH, exist_ok=True)\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    base_filename = f\"{current_date}_{PROGRAM_NAME}_{KPIS_IN_SCOPE}_{LOBS_IN_SCOPE}_Verbatim_Analysis\"\n",
    "\n",
    "    minor_version = 0\n",
    "    while True:\n",
    "        version_str = f\"v{MAJOR_VERSION:02d}.{minor_version:02d}\"\n",
    "        output_filename = f\"{base_filename}_{version_str}.xlsx\"\n",
    "        full_path = os.path.join(OUTPUT_FOLDER_PATH, output_filename)\n",
    "        if not os.path.exists(full_path):\n",
    "            break\n",
    "        minor_version += 1\n",
    "    \n",
    "    # Save the final DataFrame to the unique, versioned Excel file\n",
    "    df.to_excel(full_path, index=False)\n",
    "    print(f\"\\n✅ Successfully saved categorized results to:\")\n",
    "    print(full_path)\n",
    "else:\n",
    "    print(\"\\nSkipping categorization due to model loading or data issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b375662-8e7f-45a1-bc4f-1e225d8fbb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
